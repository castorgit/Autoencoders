{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE real data electricity latent space 16 synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE for non-supervised intrusion detection\n",
    "\n",
    "Normal Data : Syn Data <br>\n",
    "Attack Data : Real Data <br>\n",
    "1000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 12:05:04.699272: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-12 12:05:04.699295: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, kl_divergence\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_marker(row):\n",
    "    if isinstance(row['marker'], str) and 'Natural' in row['marker']:\n",
    "        return 0\n",
    "    if isinstance(row['marker'], str) and 'Attack' in row['marker']:\n",
    "        return 1\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_figures = './figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "55663\n"
     ]
    }
   ],
   "source": [
    "#path = './data/Zero_Day/'\n",
    "path = './new_data/'\n",
    "path_figures = './figures/'\n",
    "path_normal = path +'VAE_syntheticdata_normal_epoch100_1000000.csv'\n",
    "#path_normal = path +'normal.csv'\n",
    "path_attack = path + 'attack.csv' # real data\n",
    "\n",
    "normal_df = pd.read_csv(path_normal)  \n",
    "attack_df = pd.read_csv(path_attack)  \n",
    "\n",
    "normal_df['marker'] = normal_df.apply(label_marker, axis=1)\n",
    "attack_df['marker'] = attack_df.apply(label_marker, axis=1)\n",
    "\n",
    "normal_label = normal_df['marker'].to_numpy() \n",
    "attack_label = attack_df['marker'].to_numpy() \n",
    "\n",
    "print(len(normal_label))\n",
    "print(len(attack_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete marker column \n",
    "normal_df.drop(['marker'], axis=1, inplace=True)\n",
    "attack_df.drop(['marker'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal shape (1000000, 128)\n",
      "attack shape (55663, 128)\n"
     ]
    }
   ],
   "source": [
    "# each row of the dataframe is considered a sequence\n",
    "# we create a numpy array with the sequences\n",
    "normal_np = normal_df.to_numpy()\n",
    "print('normal shape',normal_np.shape)\n",
    "attack_np = attack_df.to_numpy()\n",
    "print('attack shape', attack_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_df = normal_df.replace([np.inf, -np.inf], 0)\n",
    "scaler = MinMaxScaler()\n",
    "normal_scaled = scaler.fit_transform(normal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_df = attack_df.replace([np.inf, -np.inf], 0)\n",
    "scaler = MinMaxScaler()\n",
    "attack_scaled = scaler.fit_transform(attack_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = combine_labels\n",
    "#norm_samples = df_scaled[labels == 0]  # normal data\n",
    "#attack_samples = df_scaled[labels == 1]  # attack data\n",
    "\n",
    "#norm_labels = labels[labels == 0]\n",
    "#attack_labels = labels[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55663, 128)\n",
      "(1000000, 128)\n"
     ]
    }
   ],
   "source": [
    "norm_samples = normal_scaled\n",
    "attack_samples = attack_scaled\n",
    "print (attack_samples.shape)\n",
    "print (norm_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate train set\n",
    "# training set will consist of the normal ds\n",
    "\n",
    "len_norm = len(norm_samples)\n",
    "len_norm_train = int(0.80 * len_norm)\n",
    "X_train = norm_samples[:len_norm_train]\n",
    "\n",
    "# generate test set consist of 50% attack and 50% normal\n",
    "\n",
    "X_test_norm = norm_samples[len_norm_train:]\n",
    "len_attack_test = len(X_test_norm) # we will use the same number\n",
    "X_test_attack = attack_scaled[:len_attack_test]\n",
    "\n",
    "X_test = np.concatenate([X_test_norm, X_test_attack])\n",
    "y_test = np.ones(len(X_test))\n",
    "y_test[:len(X_test_norm)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_test normal shape (200000, 128) \n",
      " X_test attack shape (55663, 128) \n",
      " X_train normal shape (800000, 128) \n",
      " X_test shape (255663, 128)\n"
     ]
    }
   ],
   "source": [
    "X_train.shape\n",
    "print(' X_test normal shape',X_test_norm.shape, '\\n', \n",
    "      'X_test attack shape', X_test_attack.shape, '\\n',\n",
    "      'X_train normal shape', X_train.shape, '\\n',\n",
    "      'X_test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use RMSE as reconstruction error (can use MAE as well)\n",
    "def get_error_term(v1, v2, _rmse=True):\n",
    "    if _rmse:\n",
    "        return np.sqrt(np.mean((v1 - v2) ** 2, axis=1))\n",
    "    #return MAE\n",
    "    return np.mean(abs(v1 - v2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reparameterization trick for the autoencoder\n",
    "\n",
    "def sample(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " original_dim :  128 \n",
      " intermediate_dim :  64 \n",
      " latent_dim :  16\n"
     ]
    }
   ],
   "source": [
    "original_dim = X_train.shape[1]\n",
    "input_shape = (original_dim,)\n",
    "intermediate_dim = int(original_dim / 2) \n",
    "latent_dim = int(original_dim / 3) \n",
    "\n",
    "#intermediate_dim = 256\n",
    "latent_dim = 16\n",
    "print(' original_dim : ', original_dim,'\\n',\n",
    "      'intermediate_dim : ', intermediate_dim, '\\n', \n",
    "      'latent_dim : ', latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           8256        ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 16)           1040        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 16)           1040        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 16)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,336\n",
      "Trainable params: 10,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# enconder >< decoder\n",
    "# encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x      = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "#x      = Dense(intermediate_dim/2, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "# use the reparameterization trick and get the output from the sample() function\n",
    "z        = Lambda(sample, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder  = Model(inputs, z, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"encoder_input:0\", shape=(None, 128), dtype=float32) at layer \"dense\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_299810/961526212.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputs\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Instantiate the decoder model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdecoder\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    230\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"encoder_input:0\", shape=(None, 128), dtype=float32) at layer \"dense\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "# decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "#x             = Dense(intermediate_dim/2, activation='relu')(latent_inputs)\n",
    "x             = Dense(intermediate_dim, activation='relu')(x)\n",
    "outputs       = Dense(original_dim, activation='sigmoid')(x)\n",
    "# Instantiate the decoder model:\n",
    "decoder       = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full VAE model\n",
    "outputs   = decoder(encoder(inputs))\n",
    "vae_model = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the KL loss function:\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    # compute the average MSE error, then scale it up, ie. simply sum on all axes\n",
    "    reconstruction_loss = K.sum(K.square(x - x_decoded_mean))\n",
    "    # compute the KL loss\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.square(K.exp(z_log_var)), axis=-1)\n",
    "    # return the average loss over all \n",
    "    total_loss = K.mean(reconstruction_loss + kl_loss)    \n",
    "    #total_loss = reconstruction_loss + kl_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training autoencoder\n",
    "opt = optimizers.Adam(learning_rate=0.0001, clipvalue=0.5)\n",
    "\n",
    "vae_model.compile(optimizer=opt, loss=vae_loss)\n",
    "vae_model.summary()\n",
    "\n",
    "results = vae_model.fit(X_train, X_train,\n",
    "                        shuffle=True,\n",
    "                        epochs=300,\n",
    "                        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['loss'])\n",
    "#plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of training vector\n",
    "X_train_pred = vae_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_vector = get_error_term(X_train_pred, X_train, _rmse=False)\n",
    "print(f'Avg error {np.mean(mae_vector)}\\nmedian error \\\n",
    "      {np.median(mae_vector)}\\n99Q: {np.quantile(mae_vector, 0.99)}')\n",
    "\n",
    "error_thresh = np.quantile(mae_vector, 0.97)\n",
    "print('error threshold >>>', error_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application of error threshold in test vector\n",
    "# A vector of anomalies is created with the points that go over the threshold\n",
    "\n",
    "X_pred = vae_model.predict(X_test)\n",
    "mae_vector = get_error_term(X_pred, X_test, _rmse=False)\n",
    "anomalies = (mae_vector > error_thresh)\n",
    "\n",
    "np.count_nonzero(anomalies) / len(anomalies)\n",
    "print('total length vector anomalies : ',len(anomalies))\n",
    "print('Number of anomalies : ', np.count_nonzero(anomalies))\n",
    "print('total length of y_test vector',len(y_test))\n",
    "print('total lenght of attacks in y_test vector', np.count_nonzero(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn classification report\n",
    "print(classification_report(y_test, anomalies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second prediction with X_test vector to be used in PCA transformation\n",
    "X_pred2 = encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA transformation to observe variance in 2 components\n",
    "\n",
    "\n",
    "#, svd_solver='arpack'\n",
    "pca = PCA(n_components=2, random_state=123)\n",
    "X_transform = pca.fit_transform(X_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure comparison PCA transformations\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,4))\n",
    "fig.suptitle('PCA transformations comparison',size=20)\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=20, hue=mae_vector, ax=ax1)\n",
    "ax1.set_xlabel('MAE Vector', size=16)\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=20, hue=anomalies, ax=ax2)\n",
    "ax2.set_xlabel('Anomalies', size = 16)\n",
    "legend_labels2, _ = ax2.get_legend_handles_labels()\n",
    "ax2.legend(legend_labels2, ['Normal', 'Anomaly'], title='Anomalies')\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=10, hue=y_test, ax=ax3)\n",
    "ax3.set_xlabel('y_test', size = 16)\n",
    "legend_labels3, _ = ax3.get_legend_handles_labels()\n",
    "ax3.legend(legend_labels3, ['Normal', 'Attack'], title='Traffic')\n",
    "plt.xlim([-10, 10])\n",
    "plt.ylim([-10, 10])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "ax.set_title('PCA transformation comparison \\n MAE Vector',size=20)\n",
    "ax.set_ylabel('Component 2', size=16)\n",
    "ax.set_xlabel('Component 1', size=16)\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=20, hue=mae_vector)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "ax.set_title('PCA transformation comparison \\n Anomalies',size=20)\n",
    "ax.set_ylabel('Component 2', size=16)\n",
    "ax.set_xlabel('Component 1', size=16)\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=20, hue=anomalies)\n",
    "legend_label, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(legend_label, ['Normal', 'Anomaly'], title='Anomalies')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "ax.set_title('PCA transformation comparison \\n Traffic Classification',size=20)\n",
    "ax.set_ylabel('Component 2', size=16)\n",
    "ax.set_xlabel('Component 1', size=16)\n",
    "sns.scatterplot(x=X_transform[:, 0], y=X_transform[:, 1], s=10, hue=y_test)\n",
    "legend_label, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(legend_label, ['Normal', 'Attack'], title='Traffic')\n",
    "plt.xlim([-10, 10])\n",
    "plt.ylim([-10, 10])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction figure\n",
    "plt.rc('legend',fontsize=14)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': np.squeeze(mae_vector),\n",
    "                        'True_class': y_test})\n",
    "\n",
    "error_df = error_df.sample(frac=1).reset_index(drop=True)\n",
    "threshold_fixed = error_thresh\n",
    "groups = error_df.groupby('True_class')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.Reconstruction_error, marker='o', ms=1, linestyle='',\n",
    "            label= \"Attack\" if name == 1 else \"Normal\")\n",
    "\n",
    "ax.hlines(threshold_fixed, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", \n",
    "          zorder=100, label='Threshold')\n",
    "plt.xlim(0,error_df.shape[0])\n",
    "# leg = ax.legend()\n",
    "# leg.set_title('Traffic',prop={'size':14})\n",
    "plt.legend(legend_label, ['Normal', 'Attack'], prop={'size': 14}, \n",
    "          loc=\"upper right\", markerscale=2., scatterpoints=1)\n",
    "plt.title(\"Reconstruction error for normal and attack data\", size=18)\n",
    "plt.ylabel(\"Reconstruction error\", size=16)\n",
    "plt.xlabel(\"Data point index\", size = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction errors for figure\n",
    "\n",
    "Global_error = np.squeeze(mae_vector)\n",
    "Attack_error = error_df[error_df['True_class']==1].Reconstruction_error.to_numpy()\n",
    "Normal_error = error_df[error_df['True_class']==0].Reconstruction_error.to_numpy()\n",
    "print(' Attack_error shape', Attack_error.shape, '\\n', \n",
    "      'Normal_error shape', Normal_error.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure error distribution\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(18,6))\n",
    "fig.suptitle('Error distribution comparison between different traffic categories',\n",
    "             size=20)\n",
    "ax1.hist(Normal_error, bins=150, color='green', alpha=0.6)\n",
    "ax1.set_xlabel('Normal error', size=14)\n",
    "ax1.set_ylabel('No of samples', size = 14)\n",
    "ax2.hist(Attack_error, bins=150, color='orange')\n",
    "ax2.set_xlabel('Attack error', size = 14)\n",
    "ax2.set_ylabel('No of samples', size = 14)\n",
    "ax3.hist(Attack_error, bins=150, color='orange')\n",
    "ax3.hist(Normal_error, bins=150, color='green', alpha=0.6)\n",
    "ax3.set_xlabel('Normal and attack', size = 14)\n",
    "ax3.set_ylabel('No of samples', size = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Paper Figure ===\n",
    "# Distribución reconstruction error \n",
    "latent_space = latent_dim\n",
    "plt.rcParams['axes.titley'] = 1.12\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "sns.kdeplot(\n",
    "    Normal_error,\n",
    "    fill    = True,\n",
    "    ax      = ax,\n",
    "    label   = 'Normal',\n",
    "    color   = 'blue'\n",
    ")\n",
    "sns.kdeplot(\n",
    "    Attack_error,\n",
    "    fill    = True,\n",
    "    ax      = ax,\n",
    "    label   = 'Attack',\n",
    "    color   = 'red'\n",
    ")\n",
    "#sns.rugplot(error_reconstruccion,  ax=ax, color='black')\n",
    "plt.suptitle('Distribution Reconstruction Error',y=0.92, \n",
    "            fontsize=16)\n",
    "ax.set_title('VAE Autoencoder latent space '+str(latent_space)+' cells', fontsize=15)\n",
    "ax.set_xlabel('Reconstruction error', fontsize = 14);\n",
    "ax.set_ylabel('Density',fontsize=14);\n",
    "ax.set_xlim(0,0.25)\n",
    "plt.legend( fontsize=16)\n",
    "plt.savefig(path_figures+'VAE_'+str(latent_space)+'_syn_ele.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis latent space with t-SNE\n",
    "\n",
    "plt.rcParams['axes.titley'] = 1.05\n",
    "tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300, init='pca', random_state=123)\n",
    "tsne_results = tsne.fit_transform(X_pred2)\n",
    "\n",
    "df_subset=pd.DataFrame(tsne_results, columns=['tsne-2d-one','tsne-2d-two']) \n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "ax.set_title('t-sne applied to latent space \\n Traffic Classification',size=20)\n",
    "ax.set_ylabel('Component 2', size=16)\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"\", [\"blue\",\"orange\"])\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=y_test,\n",
    "    alpha=1,\n",
    "    data=df_subset,\n",
    "    cmap=custom_cmap,\n",
    "    s = 8\n",
    ")\n",
    "ax.set_xlabel('Component 1', size=16)\n",
    "legend_label, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(legend_label, ['Normal', 'Attack'], title='Traffic', fontsize=12, title_fontsize=12)\n",
    "ax.set_xlim(-10,10)\n",
    "ax.set_ylim(-10,10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-sne transformation to observe variance in 3 components of latent space\n",
    "\n",
    "tsne = TSNE(n_components=3, verbose=0, perplexity=40, n_iter=300, init='pca', random_state=123)\n",
    "tsne_results = tsne.fit_transform(X_pred2)\n",
    "plt.rcParams['axes.titlepad'] = -14 \n",
    "df_subset=pd.DataFrame(tsne_results, columns=['tsne-2d-one','tsne-2d-two', 'tsne-2d-three']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-sne figure 3D\n",
    "\n",
    "plt.rcParams['axes.titley'] = .95\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax= Axes3D(fig, auto_add_to_figure=False)\n",
    "fig.add_axes(ax)\n",
    "ax.axes.set_xlim3d(left=-4, right=6)\n",
    "ax.axes.set_ylim3d(bottom=-4, top=6)\n",
    "ax.axes.set_zlim3d(bottom=-3, top=3)\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"\", [\"blue\",\"orange\"])\n",
    "sc = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], tsne_results[:, 2],\n",
    "               c=y_test, alpha = 1, cmap=custom_cmap, s=2)\n",
    "plt.title('3D t-sne applied to latent space \\n Traffic Classification',size=20)\n",
    "\n",
    "ax.set_xlabel('Component 1', size=16)\n",
    "ax.set_ylabel('Component 2', size=16)\n",
    "ax.set_zlabel('Component 3', size=16)\n",
    "# rotate the axes and update\n",
    "#fig.tight_layout()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=-10, top=-2)\n",
    "ax.view_init(10, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
